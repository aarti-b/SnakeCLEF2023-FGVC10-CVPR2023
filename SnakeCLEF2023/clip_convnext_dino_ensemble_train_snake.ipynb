{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, CLIPModel\n",
    "import torchvision.transforms as T\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_DIR = '../SnakeCLEF2023-medium_size-train/'\n",
    "VAL_DIR='../SnakeCLEF2023-medium_size-val'\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No classes: 1784\n",
      "Train set length: 145,381\n",
      "Validation set length: 10,985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k1/my0k39b95sg30r6_k0vgqk9c0000gn/T/ipykernel_30528/336587869.py:2: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_df = pd.read_csv('../snake_csv_files/SnakeCLEF_bbox_annotations_train_val_rare_diet.csv')\n"
     ]
    }
   ],
   "source": [
    "# load metadata\n",
    "train_df = pd.read_csv('../snake_csv_files/SnakeCLEF_bbox_annotations_train_val_rare_diet.csv')\n",
    "valid_df = pd.read_csv('../snake_csv_files/SnakeCLEF2023-cleaned-metadata-val.csv')\n",
    "\n",
    "\n",
    "train_df.head()\n",
    "classes = np.unique(train_df['binomial'])\n",
    "no_classes = len(classes)\n",
    "print(f'No classes: {no_classes}')\n",
    "print(f'Train set length: {len(train_df):,d}')\n",
    "print(f'Validation set length: {len(valid_df):,d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>observation_id</th>\n",
       "      <th>binomial</th>\n",
       "      <th>code</th>\n",
       "      <th>endemic</th>\n",
       "      <th>class_id</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990/Zamenis_lineatus/3001242.jpg</td>\n",
       "      <td>2670823</td>\n",
       "      <td>Zamenis lineatus</td>\n",
       "      <td>IT</td>\n",
       "      <td>True</td>\n",
       "      <td>1779</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>377</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990/Xenoxybelis_argenteus/113910655.jpg</td>\n",
       "      <td>70108926</td>\n",
       "      <td>Xenoxybelis argenteus</td>\n",
       "      <td>VE</td>\n",
       "      <td>False</td>\n",
       "      <td>1772</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>350</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990/Xenoxybelis_argenteus/113910659.jpg</td>\n",
       "      <td>70108926</td>\n",
       "      <td>Xenoxybelis argenteus</td>\n",
       "      <td>VE</td>\n",
       "      <td>False</td>\n",
       "      <td>1772</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>379</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990/Aspidelaps_lubricus/168477.JPG</td>\n",
       "      <td>117935</td>\n",
       "      <td>Aspidelaps lubricus</td>\n",
       "      <td>ZA</td>\n",
       "      <td>False</td>\n",
       "      <td>95</td>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>364</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990/Telescopus_beetzi/177365.JPG</td>\n",
       "      <td>125284</td>\n",
       "      <td>Telescopus beetzi</td>\n",
       "      <td>ZA</td>\n",
       "      <td>False</td>\n",
       "      <td>1606</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 image_path observation_id  \\\n",
       "0         1990/Zamenis_lineatus/3001242.jpg        2670823   \n",
       "1  1990/Xenoxybelis_argenteus/113910655.jpg       70108926   \n",
       "2  1990/Xenoxybelis_argenteus/113910659.jpg       70108926   \n",
       "3       1990/Aspidelaps_lubricus/168477.JPG         117935   \n",
       "4         1990/Telescopus_beetzi/177365.JPG         125284   \n",
       "\n",
       "                binomial code  endemic  class_id  xmin  ymin  xmax  ymax  \n",
       "0       Zamenis lineatus   IT     True      1779    81     7   377   319  \n",
       "1  Xenoxybelis argenteus   VE    False      1772    52     6   350   383  \n",
       "2  Xenoxybelis argenteus   VE    False      1772     0   146   379   280  \n",
       "3    Aspidelaps lubricus   ZA    False        95     4    68   364   316  \n",
       "4      Telescopus beetzi   ZA    False      1606    23     1   364   363  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_path', 'observation_id', 'binomial', 'code', 'endemic',\n",
       "       'class_id', 'xmin', 'ymin', 'xmax', 'ymax'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CLIP MODEL \n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = AutoProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "fh = open('clip_embeddings.csv', 'w')\n",
    "cvs_writer = csv.writer(fh)\n",
    "\n",
    "# write one row with headers (using `writerow` without `s` at the end)\n",
    "cvs_writer.writerow(['CLIP_embedding', 'image_path', 'observation_id', 'binomial', 'code', 'endemic',\n",
    "       'class_id', 'xmin', 'ymin', 'xmax', 'ymax'])\n",
    "                                                                                                \n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for index, row in train_df.iterrows():\n",
    "    # print(index)\n",
    "    image = Image.open(DATA_DIR+row['image_path'])\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    image_features = model.get_image_features(**inputs)\n",
    "\n",
    "    result = [image_features.tolist(), row['image_path'], row['observation_id'], row['binomial'], row['code'], row['endemic'],\n",
    "       row['class_id'], row['xmin'], row['ymin'], row['xmax'], row['ymax']]\n",
    "\n",
    "    fh = open('clip_embeddings.csv', 'a') \n",
    "    cvs_writer = csv.writer(fh)\n",
    "\n",
    "    # write row row with result (using `writerow` without `s` at the end)\n",
    "    cvs_writer.writerow(result)\n",
    "    print(' Done {}'.format(row[\"image_path\"]))\n",
    "\n",
    "    fh.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/aartibalana/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "xFormers not available\n",
      "xFormers not available\n"
     ]
    }
   ],
   "source": [
    "patch_h = 40\n",
    "patch_w = 40\n",
    "feat_dim = 1536 # vitg14\n",
    "\n",
    "'''\n",
    "DINOV2 MODEL\n",
    "'''\n",
    "dinov2_vitg14 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitg14').to(device)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "Dataset class \n",
    "\n",
    "'''\n",
    "class SnakeTrainDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, transform = None):\n",
    "        self.data=data\n",
    "        self.transform=transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image = self.data.iloc[index]\n",
    "        img = Image.open(DATA_DIR+image.image_path).convert(\"RGB\")\n",
    "        # img=TF.adjust_sharpness(img, 20.0)\n",
    "        label = torch.tensor(image.class_id)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return (img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = T.Compose([\n",
    "    T.GaussianBlur(9, sigma=(0.1, 2.0)),\n",
    "    T.Resize((patch_h * 14, patch_w * 14)),\n",
    "    T.CenterCrop((patch_h * 14, patch_w * 14)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "train_dataset = SnakeTrainDataset(train_df, transform=transform_train) # data augmentation. set augmentations = None to disable augmentations\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 6, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (imgs, targs) in enumerate(tqdm(train_dataloader)):\n",
    "        imgs = imgs.to(device)\n",
    "        targs = targs.to(device)\n",
    "        with torch.no_grad():\n",
    "            features=dinov2_vitg14.forward_features(imgs)['x_norm_clstoken']\n",
    "\n",
    "            print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CONVNEXT XXLARGE\n",
    "\n",
    "'''\n",
    "\n",
    "model = timm.create_model(\n",
    "    'convnext_xxlarge.clip_laion2b_soup_ft_in1k',\n",
    "    pretrained=True,\n",
    "    num_classes=0,  # remove classifier nn.Linear\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in train_df.iterrows():\n",
    "\n",
    "    image = Image.open(DATA_DIR+row['image_path'])\n",
    "\n",
    "    output = model(transforms(image).unsqueeze(0))  \n",
    "\n",
    "\n",
    "    output = model.forward_features(transforms(image).unsqueeze(0))\n",
    "    # output is unpooled, a (1, 3072, 8, 8) shaped tensor\n",
    "\n",
    "    output = model.forward_head(output, pre_logits=True)\n",
    "    # output is a (1, num_features) shaped tensor\n",
    "\n",
    "    print(output.shape)\n",
    "    print(row['binomial'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MAke a dataset function and dataloader which outputs concatenated embeddings and class_id and binomial_names\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Example image embeddings of shape \n",
    "'''\n",
    "TODO :\n",
    "'''\n",
    "embedding_1 = 3#CLIP\n",
    "embedding_2 = 3 #DINO\n",
    "embedding_3 = 3#CONVXNEXT\n",
    "\n",
    "# Concatenate the embeddings\n",
    "concatenated_embeddings = torch.cat([embedding_1, embedding_2, embedding_3], dim=0)\n",
    "\n",
    "# Define the classifier\n",
    "num_classes = 1784  # Example: number of classes\n",
    "classifier = nn.Sequential(\n",
    "    nn.Linear(728 + 512 + 256 + 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(512, num_classes)\n",
    ")\n",
    "\n",
    "\n",
    "# Set up optimizer and loss function\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "classifier.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in dataloader: #add dataloader\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        embeddings = torch.cat([embedding_1, embedding_2, embedding_3], dim=1)\n",
    "        logits = classifier(embeddings)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f615393229ba2fb2db268572fee62c0b9d9268a262e5ddcf86870f4fdd32986a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('stereo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
